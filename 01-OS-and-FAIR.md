---
title: "Introduction to Open Science and FAIR principles"
teaching: 35
exercises: 20
---

:::::::::::::::::::::::::::::::::::::: questions 

- What is Open Science?
- How can I benefit from Open Science?
- What are the FAIR guidelines?
- Why being FAIR matters?

::::::::::::::::::::::::::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::: objectives

- Identify parts of the Open Science movement, their goals and motivations
- Explain the main benefits of Open Science
- Recognize the barriers and risks in the adoption of Open Science practices
- Recognize typical issues that prevent data re-use
- Understand the FAIR principles


::::::::::::::::::::::::::::::::::::::::::::::::



(16 min teaching)

Science works best by exchanging ideas and building on them. Most efficient science involves both questions and
experiments being made as fully informed as possible, which requires the free exchange of data and information.

All practices that make knowledge and data **freely available** fall under the umbrella-term of **Open Science/Open
Research**. It makes science **more reproducible, transparent, and accessible**. As science becomes more open, the way
we conduct and communicate science changes continuously.

::::::::::::::::::::::::::::::::::::: callout

## What is Open Science

Open science is the movement to make scientific research (including publications, data, physical samples, and software)
and its dissemination **accessible to all levels** of an inquiring society,
amateur or professional.

Open Science represents a new approach to the scientific process based on **cooperative work**
and new ways of diffusing knowledge by **using digital technologies** and new collaborative tools.

Open science is **transparent and accessible knowledge**
that is shared and developed through collaborative networks.

Characteristics:

* Using web-based tools to facilitate information exchange and scientific collaboration
* Transparency in experimental methodology, observation, and collection of data
* Public availability and reusability of scientific data, methods and communications
* various outputs and audiences

:::::::::::::::::::::::::::::::::::::::::::::



### What is the Open Science movement?


The distribution of knowledge has always been subject to improvement.
Whilst the internet was initially developed for
military purposes, it was hijacked for communication between scientists, which provided a viable route to change the
dissemination of science.

The momentum has built up with a change in the way science is communicated to reflect what
research communities are calling for – solutions to the majority of problems (e.g. impact factors, data reusability,
reproducibility crisis, trust in the public science sector etc...) that we face today.

Open Science is the movement to increase transparency and reproducibility of research, through using
the open best practices.


![Figure 1. Open Science Building Blocks](../fig/OpenScienceBuildingBlocks.jpg)

*After [Gema Bueno de la Fuente](https://www.fosteropenscience.eu/content/what-open-science-introduction)*

### Open Science Building Blocks

* **Open Access:** Research outputs hosted in a way that make them accessible for everyone. Traditionally Open Access
  referred to journal articles, but now includes books, chapters or images.

* **Open Data:** Data freely and readily available to access, reuse, and share.
  Smaller data sets were often accessible as
  supplemental materials by journals alongside articles themselves.
  However, they should be hosted in dedicated platforms for
  more convenient and better access.

* **Open Software:** Software where the source code is made readily available;
  others are free to use, change, and
  share. Some examples of these including the coding language and supporting software R and RStudio,
  as well as image analysis software such as Fiji/ImageJ.

* **Open Notebooks:** Lab & notebooks hosted online, readily accessible to all. These are popular among some of the
  large funding bodies and allow anyone to comment on any stage of the experimental record.

* **Open Peer Review:** A system where peer review reports are published alongside the body of work. This can include
  reviewers' reports, correspondence between parties involved, rebuttals, editorial decisions etc...
  
* **Citizens Science:** Lay people become involved in scientific research, most commonly in data collection or image analysis. Platforms such as [zooniverse.org](https://www.zooniverse.org/) help connect projects with lay people interested in playing an active role in research, which  can help generate and/or process data which would otherwise be unachievable by one single person.

* **Scientific social networks:** Networks of researchers, which often meet locally in teams, but are also connected online, foster open discussions on scientific issues. Online, many people commonly use traditional social media platforms for this, such as Twitter, Instagram, various sub-reddits, discussion channels on Slack/Discord etc..., although there are also more dedicated spaces such as [researchgate.net](https://www.researchgate.net/).

* **Open Education resources:** Educational materials that are free for anyone to access and use to learn from. These can be anything from talks, instructional videos, and explanations posted on video hosting websites (e.g. YouTube), to entire digital textbooks written and then published freely online. 


### Benefits of Open Science

Possible benefits and consequences for each OS module:

**Open Access**

* speed of knowledge distribution
* leveling field for underfunded sites which otherwise wouldn’t be able to navigate the paywall
* prevent articles being paid for ‘thrice’ (first to produce, second to publish, third to access) by institutions.
* greater access to work by others, increasing chance for exposure & citations
* access to work by lay audiences, thus increases social exposure of research

**Open Data**

* ensures data isn’t lost overtime - reusability
* acceleration of scientific discovery rate
* value for money/reduced redundancy
* permits statistical re-analysis of the data to validate findings
* gives access to datasets which were not published as papers (e.g. negative results, large screening data sets)
* provides an avenue to generate new hypotheses
* permits combination of multiple data sources to address questions, provides greater power than a single data source

**Open Software**

* great source to learn programming skills
* the ability to modify creates a supportive community of users and rapid innovation
* saves time
* faster bug fixes
* better error scrutiny
* use of the same software/code allows better reproducibility between experiments
* need funds to maintain and update software

**Open Notebooks**

* 100% transparent science, allowing input from others at early stages of experiments
* source of learning about the process of how science is actually conducted
* allows access to experiments and data which otherwise never get published
* provides access to ‘negative’ results and failed experiments
* anyone, anywhere around the world, at any time, can check in on projects, including many users simultaneously
* possibility of immediate feedback
* thorough evidence of originality of ideas and experiments, negating effect of ‘scooping’

**Open Peer Review**

* visibility leads to more constructive reviews
* mitigates against editorial conflicts of interest and/or biases
* mitigates against reviewers conflicts of interest and/or biases
* allows readers to learn/benefit from comments of the reviewers

**Open Educational Materials**

* Foster collaboration between educators/others
* Show clearly how method was taught (e.g. Carpentries materials) which can be reproduces anywhere, anytime
* protects materials from becoming technologically obsolete
* authors preparing the material or contribute all earn credit (e.g. GitHub)
* recycle animations and material that is excellent (why reinvent the wheel?)

### Motivation: Money (8 min teaching)

One has to consider the moral objectives that
accompany the research/publication process: charities/taxpayers pay to fund research, these then pay again to access the
research they already funded.

From an economic point of view, scientific outputs generated by public research are a public good that everyone should be able to use at no cost.

According to EU report ["Cost-benefit analysis for FAIR research data"](https://op.europa.eu/en/publication-detail/-/publication/d375368c-1a0a-11e9-8d04-01aa75ed71a1),
€10.2bn is lost every year because of not accessible data (plus additional 16bn if accounting for re-use and research quality).

The goals of Open Science is to make research and research data available to e.g.
charities/taxpayers who funded this research.

The majority of larger UK and other countries' funding bodies are now making
Open Access publication conditional upon funding. 
As the results Open Access is adopted by majority of researcher and is the most proliferated part of the OS movement.



### Personal motivators

Open Science is advantageous to many parties involved in science (including
researcher community, funding bodies, the public even journals), which is leading to a push for the widespread adoption of
Open Science practices.

Large UK funding bodies such as The Wellcome Trust are big supporters of Open Science.
We can see with the example of Open Access, that once enforced by funders (*the stick*)
there is a wide adoption. But what about the personal motivators, *the carrots*.

::::::::::::::::::::::::::::::::::::: challenge 

## Exercise 1: Personal benefits of being "open" (4 min)

Below are some personal benefits to adopting Open Science practices.
Read through them which of them are the strongest motivators for you.
Select two the most important/attractive for you and mark them with +1,
select the two least important for you and mark them with 0

* receive higher citations
* complying with funders’ policies
* get extra value from your work (e.g. collaborators, reuse by modellers, ML specialists)
* demonstrate research impact
* save own time (reproducibility but also communication overhead)
* become pioneers
* distinguish yourself from the crowd
* plan successful research proposals
* gain valuable experience
* form community
* increased speed and/or ease of writing papers
* speed up and help with peer review
* build reputation and presence in the science community
* evidence of your scientific rigour and work ethic
* avoid embarrassment/disaster when you cannot reproduce your results

Can you think of other benefits?
How personal benefits of Open Science compare to the benefits
for the (scientific) society?

:::::::::::::::::::::::::::::::::::::

(3 min teaching)

The main difference between the public benefits of Open Science practices
and the personal motivators of outputs creators, that the public can
benefit almost instantly from the open resources.

However, the advantages for data creator comes with a delay, typically counted
in years. For example, building reputation will not happen with one dataset,
the re-use also will lead to citations/collaboration after the next research
cycle.

### DORA - declaration of Research Assessment

#### Principle of DORA:

The Declaration on Research Assessment (DORA) emerged from a recognition of the limitations and biases associated with journal-based metrics, such as Journal Impact Factors. Motivated by a desire to promote fair and transparent evaluation practices, DORA advocates for assessing research based on its intrinsic merits rather than the venue of publication. Its realization signifies a paradigm shift in how we measure the impact and significance of scholarly work, emphasizing the importance of quality, openness, and broader societal impacts.

### Adoption of Funders:

Funders worldwide are increasingly recognizing the importance of embracing DORA principles in their assessment criteria. Institutions like Wellcome and Cancer Research UK have led the charge by incorporating DORA principles into their funding applications. By prioritizing factors such as research outputs, contributions to mentorship, and plans for public engagement, these funders are signaling a commitment to supporting research that generates meaningful knowledge, fosters collaborations, and contributes to societal well-being.

### Narrative CV as a DORA-Compliant Assessment Tool:

The Narrative CV offers a DORA-compliant approach to evaluating researchers, focusing on key dimensions that reflect the principles of DORA:

-  Generation of Knowledge: Acknowledging diverse outputs such as datasets, patents, and software.
-  Development of Individuals and Collaborations: Highlighting mentorship and collaborative endeavors that enrich the research ecosystem.
-  Supporting Broader Society and the Economy: Demonstrating the societal and economic impacts of research beyond academic circles.
-  Supporting the Research Community: Engaging in open science practices and ensuring the accessibility of research outputs.

In this assessment framework, special attention is paid to Open Science practices, ensuring that research outputs are openly available to maximize their impact and visibility. Additionally, new metrics such as retweets, online views and downloads, discussions, and presence in mass media and technology platforms are considered to provide a more comprehensive understanding of research impact in today's digital age.

Embracing Open Practices and adhering to DORA principles not only aligns with ethical research conduct but also enhances the credibility and impact of scholarly work. As evidenced by the Narrative CV and the adoption of DORA principles by leading funders, the research community is moving towards a more transparent and equitable assessment paradigm. Ultimately, the choice to embrace Open Practices is not only a matter of integrity but also a recognition that authenticity and transparency are essential drivers of scientific progress. After all, as timestamps remind us, faking Open Practices is far more challenging than simply adhering to them.

### Barriers and risks of OS movement:

::::::::::::::::::::::::::::::::::::: challenge 

## Exercise 2: Why we are not doing Open Science already (4 min)

Discuss Open Science barriers, mention the reasons for not already being open:


:::::::::::::::::::::::: solution

 - sensitive data (anonymising data from administrative health records can be difficult)
 - IP
 - sensitive data
 - lack of expertise
 - the costs in $ and in time
 - novelty of data
 - lack of confidence (the fear of critics)
 - misuse (fake news)
 - it is not mandatory
 - lack of credit (publishing negative results is of little benefit to you)

::::::::::::::::::::::::

:::::::::::::::::::::::::::::::::::::

(9 min teaching)

It may seem obvious that we should adopt open science practices, but there are associated challenges with doing so.

Sensitivity of data is sometimes considered a barrier.
Shared data needs to be compliant with data privacy laws, leading
many to shy away from hosting it publicly. Anonymising data to desensitise it can help overcome this barrier.

The potential for intellectual property on research can dissuade some from adopting open practices. Again, much can be
shared if the data is filtered carefully to protect anything relating to intellectual property. 

Another risk could be seen with work on Covid19: pre-prints.
A manuscript hosted publicly prior to peer review, may
accelerate access to knowledge, but can also be misused and/or misunderstood. This can result in political and health
decision making based on faulty data, which is counter to societies’ best interest.

One concern is that opening up ones
data to the scientific community can lead to the identification of errors, which may lead to feelings of
embarrassment. However, this could be considered an upside - we should seek for our work to be scrutinized and errors to
be pointed out, and is the sign of a competent scientist.
One should rather have errors pointed out rather than risking
that irreproducible data might cause
even more embarrassment and disaster.

One of **the biggest barriers are the costs** involved in "being Open".
Firstly, making outputs readily available and usable to others takes time
and significant effort. Secondly, there are costs of hosting and storage.
For example, microscopy datasets reach sizes in terabytes,
making such data accessible for 10 years involves serious financial commitment.


# Being FAIR

We have seen how Open practices can benefit both scientific community as
a whole and individual practitioner.
The wide adoption of Open Access principles has resulted in an easy access
to recent biomedical publications.
Unfortunately, the same cannot be said about data and software
that accompanies those publications.

::::::::::::::::::::::::::::::::::::: callout

## What is data

Although scientific data is a very broad term, we still encounter
groups who (wrongly) believe they do not have data!
Data does not mean Excel files with recorded measurements from a machine.
Data also includes:

* images, not only from microscopes
* information about biological materials, like strain or patient details
* biological models
* recipes, laboratory and measurement protocols
* scripts, analysis procedures, and custom software can also be considered data

However, there are specific recommendations on how to deal with code.

::::::::::::::::::::::::::::::::::::: 

Let's have a look how challenging it can be to access and use
data from published biological papers.

::::::::::::::::::::::::::::::::::::: challenge

## Exercise 3: Impossible protocol (4 min)

You need to do a western blot to identify Titin proteins,
the largest proteins in the body, with a molecular weight of 3,800 kDa.
You found an antibody sold by Sigma Aldrich that has been validated
in western blots and immunofluorescence. Sigma Aldrich lists the
[Yu et al., 2019](https://doi.org/10.1002/acn3.50831)
paper as reference.

Find details of how to separate and transfer this large protein in
the reference paper.

* Hint 1: Methods section has a Western blot analysis subsection.  
* Hint 2: Follow the references.  

Would you say that the methods was Findable? Accessible? Reusable?

:::::::::::::::::::::::: solution

## Solution

 * Ref 17 will lead you to [this
    paper](https://doi.org/10.1002/ana.24102), which first of all is
    not Open Access
 * Access the paper through your institutions (if you can) and find
    the 'Western Blotting' protocol on page 232 which will show the
    following (Screenshot from the methods section from [Evilä et al 2014](https://doi.org/10.1002/ana.24102)):
 * ![Figure 1. Impossible Protocol](./fig/impossible_protocol.png)
 * "Western blotting were performed according to standard methods." -
    with no further reference to these standard methods, describing
    these methods, or supplementary material detailing these methods
 * This methodology is unfortunately a true dead end and we thus
     can't easily continue our experiments!

:::::::::::::::::::::::::
:::::::::::::::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::: challenge

## Impossible numbers

[Ikram 2014](https://doi.org/10.1093/jxb/err244) paper contains data about various metabolites in
different accessions (genotypes) of Arabidopsis plant. 
You would like to calculate average nitrogen content in plants grown under normal and nitrogen 
limited conditions. 
Please calculate the average (over genotypes) nitrogen content for the two experimental conditions.

* Hint 1. Data are in Supplementary data   
* Hint 2. Search for nitrogen in paper text to identify the correct data column.  

:::::::::::::::::::::::: solution

## Solution

* Finding the right table and column containing the relevant data is already problematic as the headers are obscured so they need to decoded using manuscript
* Data in pdf table so they cannot be readily used in calculations
* Depending on the software used to open (and the way the pdf was created), the local machine international settings, copying the data into Excel can bring unexpected results
![Figure 2. Pdf data copied to Excel](./fig/03-average_to_excel1.png)  
*Data needs parsing after coping to Excel*
![Figure 2. The same data copied to Excel with polish locale](./fig/03-average_to_excel1.png)  
*The same data copied to Excel with polish locale has been converted to dates*
* In general pdf tables cannot be read programmatically from R or Python.

:::::::::::::::::::::::::
:::::::::::::::::::::::::::::::::::::



